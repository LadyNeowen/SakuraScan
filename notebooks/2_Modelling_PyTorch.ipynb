{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ac10b5-86f4-457a-be04-ba0551dfc884",
   "metadata": {},
   "source": [
    "# SakuraScan – Modelling (PyTorch)\n",
    "\n",
    "## Objectives\n",
    "- Train a binary image classifier to distinguish healthy cherry leaves from leaves with powdery mildew.\n",
    "- Use transfer learning with a pretrained CNN (ResNet18) for robust performance.\n",
    "- Save the trained model for use in the SakuraScan Streamlit dashboard.\n",
    "\n",
    "## Inputs\n",
    "- Image dataset stored in `Data/source_images/healthy` and `Data/source_images/powdery_mildew`.\n",
    "\n",
    "## Outputs\n",
    "- Trained PyTorch model weights saved to `app_pages/src/models/sakuramodel_resnet18.pth`.\n",
    "- Printed training and validation accuracy and loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8deb862a-98ba-422d-be27-665e19ca2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model training script for SakuraScan using PyTorch and transfer learning.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda1ab5a-fe07-4097-89aa-e0f40fe844d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set up paths, constants, and devive configuration.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root is the parent folder of the notebooks directory\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"Data\" / \"source_images\"\n",
    "MODEL_DIR = PROJECT_ROOT / \"app_pages\" / \"src\" / \"models\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"sakuramodel_resnet18.pth\"\n",
    "\n",
    "BATCH_SIZE = 32  # Number of images processed in one training step.\n",
    "NUM_EPOCHS = 8  # How many full passes the model makes over the entire training dataset.\n",
    "LEARNING_RATE = 1e-4  # Controls how big the weight updates are during training.\n",
    "VAL_SPLIT = 0.2  # Fraction of the dataset reserved for validation to evaluate model performance.\n",
    "IMAGE_SIZE = 224  # Target resolution for all input images (ResNet models expect 224×224 pixels).\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c1853a2-7951-42cb-b536-45fd72e0e4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\NeosT\\OneDrive\\Skrivbord\\VsCode-Projects\\SakuraScan\\SakuraScan\n",
      "DATA_DIR: C:\\Users\\NeosT\\OneDrive\\Skrivbord\\VsCode-Projects\\SakuraScan\\SakuraScan\\Data\\source_images\n",
      "Exists DATA_DIR? True\n",
      "MODEL_DIR: C:\\Users\\NeosT\\OneDrive\\Skrivbord\\VsCode-Projects\\SakuraScan\\SakuraScan\\app_pages\\src\\models\n",
      "Exists MODEL_DIR? True\n"
     ]
    }
   ],
   "source": [
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"Exists DATA_DIR?\", DATA_DIR.exists())\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n",
    "print(\"Exists MODEL_DIR?\", MODEL_DIR.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db46169-475f-46c8-86c6-26466dc1060b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['healthy', 'powdery_mildew']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create training and validation datasets and dataloaders using ImageFolder.\n",
    "\"\"\"\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Only resize + normalize for validation\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load all images with a temporary transform (updated per split)\n",
    "full_dataset = datasets.ImageFolder(root=str(DATA_DIR), transform=train_transform)\n",
    "\n",
    "class_names: List[str] = full_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10493c55-38d0-4d47-868e-dfb3720ad128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872e629-ee4f-463c-ab95-58b4d2dc46f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
